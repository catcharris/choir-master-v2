# 기술백서: 초정밀 제로-레이턴시 네이티브 동기화 아키텍처 (True T=0 Native Sync Architecture)

## 1. 개요 (Abstract)
본 기술백서는 클라우드 환경 기반의 다중 모바일 단말(스마트폰 등)을 이용한 원격 합창 및 앙상블 시스템에서, 별도의 지연 시간 보정 연산이나 타임 스탬프 추적 없이 하드웨어 수준에서 완벽한 오디오 샘플 동기화(Zero-Latency Sync)를 달성하는 "True T=0 하드웨어 이벤트 구동 방식"에 대해 기술합니다.

---

## 2. 기존 기술의 한계 (Limitations of Prior Art)
원격 환경의 수많은 단말기에서 동시에 녹음을 시작하고, 이를 클라우드 서버에서 믹스다운(Mixdown)하여 하나의 합창 파일로 생성하는 시스템에서는 **단말기별 녹음 시작 시간의 물리적 편차**가 가장 큰 기술적 난제입니다.

### 2.1. 서버-클라이언트 시간 동기화(NTP) 방식의 오차
기존 시스템은 마스터 기기가 "정확히 미래의 특정 시점(예: 현재 시간+1.5초)에 반주(MR)를 재생하고 녹음을 시작하라"고 명령하는 방식을 채택합니다. 
그러나 각 단말기 기종, 운영체제(iOS/Android), 그리고 브라우저 성능에 따라 **오디오 버퍼를 할당하고 권한을 깨우는 데 소요되는 시간(Initialization Latency)이 완전히 다릅니다**. 특히 iOS의 강력한 하드웨어 에코 캔슬링(AEC) 및 백그라운드 프로세스 간섭으로 인해 지시된 시간에 100% 동일하게 녹음이 시작되지 못하며, 이는 50~200ms 단위의 무작위적인 싱크 밀림을 유발합니다.

### 2.2. 메타데이터 후처리(Post-Processing) 연산의 한계
이를 극복하기 위해 녹음이 실제로 시작된 '지연 시간(Offset)'을 측정하여 파일의 메타데이터나 파일명(`_offset_1482ms.wav`)에 새겨 클라우드로 보내는 방식이 제시되었습니다. 
하지만 이 방식은 **재생 및 믹스다운 시 모든 트랙에 대해 개별적인 수학 연산과 타임라인 오프셋 스케줄링(`setTimeout`, `source.start(offset)`)을 강제**하게 되어 클라우드 서버의 부하를 높이고 오차 범위를 남기는 수학적 접근의 한계가 존재합니다.

---

## 3. 핵심 발명 원리: 이벤트 구동형 True T=0 락 (Event-Driven True T=0 Lock)
본 시스템이 새롭게 제안하는 동기화 메커니즘은 그 어떠한 **"시간(Time)"이나 "연산(Math)"에 의존하지 않는 물리적인 종속(Physical Chain) 구조**입니다.

### 3.1. 마이크 하드웨어 생명주기(Lifecycle)와의 직접 결합
클라이언트(위성) 기기는 마스터로부터 `START_RECORD` 명령을 받는 즉시 "시간 지연 없이" 마이크 입력 하드웨어를 활성화(MediaRecorder `.start()` 또는 AudioWorklet `.start()`)합니다.
이 때 가장 핵심적인 특허 기술은 **"기준 음원(MR)의 재생 트리거를 외부 시계 타이머가 아닌, 스마트폰 오디오 캡처 하드웨어의 `.onStart` 이벤트 내부에 삽입하여 강제 종속시키는 것"**입니다.

```typescript
// [특허 청구 핵심 로직: True T=0 Native Sync]
startRecording(() => { 
    // 하드웨어가 "최초의 오디오 샘플"을 캡처하기 시작한 정확한 찰나
    if (isMrReady) {
        playBackingTrack(); // 즉시 MR 반주 재생 시작
    }
});
```

### 3.2. 오프셋 매칭(Offset Matching)에서 제로 타임라인(Zero Timeline)으로의 패러다임 전환
- 사용자의 이어폰이나 스피커로 첫 번째 MR 소리가 울려 나오는 그 순간(`playBackingTrack()`), 마이크는 정확히 그 때부터 사용자의 숨소리와 목소리를 담아 0.0초 단위를 생성(`startRecording`)하고 있습니다.
- 결과적으로 생성된 오디오 파일(Blob)의 0.0초 지점과, 재생된 MR 반주의 0.0초 지점은 **어떤 단말기, 어떤 지연 시간을 겪었든 상관없이 하드웨어 수준에서 완벽하게 일치된 동일 선상**에 서게 됩니다.

---

## 4. 클라우드 믹스다운 적용 (Cloud Mixdown Application)
True T=0 방식으로 업로드된 수백 개의 객체 음원은 더 이상 복잡한 오프셋 역연산을 필요로 하지 않습니다. 

클라우드 렌더링 엔진(OfflineAudioContext)은 다음과 같이 극도로 단순하며 오차 확률 0%의 무결점 믹스다운을 수행합니다.
1. 마스터 기준 음원(MR)과 단원들의 녹음 파일을 불러옵니다.
2. 모든 개별 `.wav` / `.webm` 파일의 타임라인을 계산 없이 일괄적으로 `source.start(0)` 명령어로 렌더링 시작점에 뿌립니다.
3. 개별 파일 자체가 이미 "MR 재생 시작과 정확히 동시에 캡처된 결과물"이므로, 타임라인을 0으로 맞추어 한 번에 재생하는 것만으로 완벽한 하모니가 구현됩니다.

---

## 5. 결론 및 특허 명세 활용 (Patent Claim Reference)
이 아키텍처는 스마트 기기 스펙트럼이 매우 넓고 불안정한 모바일 웹 애플리케이션 환경에서, 다가오는 예측 불가능한 지연(Delay)을 파악하여 보상하려 했던 기존의 관점을 뒤집은 방식입니다.
**"지연(Delay)을 보상하는 것이 아니라, 지연 과정 자체를 통과한 최종 하드웨어 캡처 이벤트 시점을 MR 재생의 시작점으로 락(Lock)을 걸어 기준 시점을 동기화한다"**는 것이 본 시스템의 고유한 권리 범위이며, 이는 다중 분산 환경에서의 글로벌 오디오 동기화 품질을 무한에 가깝게 향상시키는 혁신 프로세스로 입증되었습니다.
